{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6d3dbe-7ee8-4923-8384-b905761aa0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3212e3cd-c8b8-48e6-9840-5338406faa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_classes, dropout):\n",
    "        super(Student, self).__init__()\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(out_channels, 30),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(30, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = self.conv_1(x)\n",
    "        out_2 = self.conv_2(out_1)\n",
    "        out_3 = torch.mean(out_2, dim=(2, 3))  \n",
    "        out_4 = self.classifier(out_3)\n",
    "        \n",
    "        return out_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3662280-d674-4400-8527-f6a1eb47e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Student(3, 32, 10, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c82b8065-8c59-48cd-a1b1-417c7be6df15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Student(\n",
       "  (conv_1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (conv_2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=30, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=30, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model/cifar10_github/epoch_99.bin'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c7b0ab-1c4d-4115-90e1-f7b84966e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(dataloader, model, loss_fn):\n",
    "    loss, accuracy = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            y_hat = model(X)\n",
    "            loss += loss_fn(y_hat, y).item()\n",
    "            accuracy += (y_hat.argmax(1) == y).type(torch.float).sum().item()\n",
    "    loss = loss / len(dataloader.dataset)\n",
    "    accuracy = accuracy / len(dataloader.dataset)\n",
    "    return (loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc70436-9316-4ca2-b42a-56337a837448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR10_dataset():\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    cifar10_path = './data'\n",
    "    cifar10_train = torchvision.datasets.CIFAR10(root=cifar10_path, train=True, transform=transform, download=True)\n",
    "    cifar10_test = torchvision.datasets.CIFAR10(root=cifar10_path, train=False, transform=transform)\n",
    "    cifar10_splitted_train, cifar10_validation = torch.utils.data.random_split(\n",
    "        cifar10_train, [45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "    return (cifar10_train, cifar10_test, cifar10_splitted_train, cifar10_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5596020b-e4b7-4964-899b-b918580ff2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataloaders(dataset, batch_size, shuffle_train=True):\n",
    "    train_dataset, test_dataset, splitted_train_dataset, validation_dataset = dataset\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                batch_size = batch_size,\n",
    "                                shuffle = shuffle_train,)\n",
    "    test_dataloader = DataLoader(test_dataset,\n",
    "                                batch_size = 100,\n",
    "                                shuffle = False,)\n",
    "    splitted_train_dataloader = DataLoader(splitted_train_dataset,\n",
    "                                batch_size = batch_size,\n",
    "                                shuffle = shuffle_train,)\n",
    "    validation_dataloader = DataLoader(validation_dataset,\n",
    "                                batch_size = 100,\n",
    "                                shuffle = False,)\n",
    "\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = train_dataloader\n",
    "    dataloaders['test'] = test_dataloader\n",
    "    dataloaders['splitted_train'] = splitted_train_dataloader\n",
    "    dataloaders['validation'] = validation_dataloader\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acb220db-c52a-41a3-93ae-ad5a45ca6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_num(model, trainable = True):\n",
    "    if trainable:\n",
    "        num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        num =  sum(p.numel() for p in model.parameters())\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dfd1b66-f0a9-4217-96f9-d1b11eae736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = load_CIFAR10_dataset()\n",
    "dataloaders = construct_dataloaders(dataset, 100, shuffle_train=True)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "429624c7-34fb-440b-9482-1fa94fe7fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dataloaders['splitted_train']\n",
    "validation_dataloader = dataloaders['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15b67a38-fa89-47e2-b619-9b99a031502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loss, tr_accuracy = evaluate_model(train_dataloader, model, loss_fn)\n",
    "va_loss, va_accuracy = evaluate_model(validation_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2110c1df-5ef3-459a-a7b1-3fe8a3bbcba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.012904320503605737, 0.5353555555555556)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_loss, tr_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5dd550e-1027-4218-af59-b0d77af9182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.013179720997810365, 0.5298)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_loss, va_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2df9626-a8d3-4e12-86c9-d2cd92bd0756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11444"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_parameter_num(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c1d94-3322-4d04-a098-3ce3613dbd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
