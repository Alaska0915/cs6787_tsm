{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import transformers, datasets, accelerate, tensorboard, evaluate\n",
    "from models import Student\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from util import *\n",
    "from loss import LossCalulcator\n",
    "from pretrained_kd import *\n",
    "from datasets import Array3D, ClassLabel, Features, load_dataset, Image\n",
    "from matplotlib import pyplot\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, ViTFeatureExtractor, ViTModel\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 50\n",
    "lr = 0.001\n",
    "lr_stepsize = 20\n",
    "batch_size = 500\n",
    "test_batch_size = 100\n",
    "temperature=2\n",
    "alpha=0.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "# from transformers import EfficientNetImageProcessor, EfficientNetForImageClassification\n",
    "\n",
    "\n",
    "# import timm\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('nateraw/vit-base-patch16-224-cifar10')\n",
    "teacher = ViTForImageClassification.from_pretrained('nateraw/vit-base-patch16-224-cifar10')\n",
    "\n",
    "\n",
    "# processor = EfficientNetImageProcessor.from_pretrained(\"google/efficientnet-b4\")\n",
    "# teacher = EfficientNetForImageClassification.from_pretrained(\"google/efficientnet-b4\")\n",
    "\n",
    "# processor = AutoImageProcessor.from_pretrained(\"ahsanjavid/convnext-tiny-finetuned-cifar10\")\n",
    "# teacher = AutoModelForImageClassification.from_pretrained(\"ahsanjavid/convnext-tiny-finetuned-cifar10\")\n",
    "\n",
    "# processor = AutoImageProcessor.from_pretrained(\"aaraki/vit-base-patch16-224-in21k-finetuned-cifar10\")\n",
    "# teacher = AutoModelForImageClassification.from_pretrained(\"aaraki/vit-base-patch16-224-in21k-finetuned-cifar10\")\n",
    "# feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85806346\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in teacher.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student = Student(3, 32, 10, 0.2)\n",
    "student.load_state_dict(torch.load('model/cifar10_github/epoch_99.bin'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Normalize, Resize, Compose\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "transforms_cifar = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "dataset['train'] = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar)\n",
    "dataset['test'] = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar)\n",
    "dataset['raw_train'] = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "# split = dataset['train'].train_test_split(test_size=(5000.0/50000), seed=42)\n",
    "\n",
    "# dataset['splitted_train'] = split['train']\n",
    "# dataset['validation'] = split['test']\n",
    "\n",
    "preprocessed_dataloaders={}\n",
    "preprocessed_dataloaders['train'] = torch.utils.data.DataLoader(dataset['train'], batch_size=batch_size)\n",
    "preprocessed_dataloaders['test'] = torch.utils.data.DataLoader(dataset['test'], batch_size=test_batch_size)\n",
    "preprocessed_dataloaders['raw_train'] = torch.utils.data.DataLoader(dataset['raw_train'], batch_size=batch_size)\n",
    "\n",
    "# preprocessed_dataloaders['validation'] = torch.utils.data.DataLoader(dataset['validation'], batch_size=test_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# dataset = load_dataset(\"cifar10\")\n",
    "# split = dataset['train'].train_test_split(test_size=(5000.0/50000), seed=42)\n",
    "# # split2 = dataset['train'].train_test_split(test_size=(5000.0/49000))\n",
    "# dataset['splitted_train'] = split['train']\n",
    "# # dataset['extra'] = split2['train']\n",
    "# dataset['validation'] = split['test']\n",
    "\n",
    "\n",
    "# def preprocess_images(examples):\n",
    "#     # get batch of images\n",
    "#     images = examples['img']\n",
    "#     examples['img'] = [np.array(image) for image in examples['img']]\n",
    "#     # convert to list of NumPy arrays of shape (C, H, W)\n",
    "#     images = [np.array(image, dtype=np.uint8) for image in images]\n",
    "#     images = [np.moveaxis(image, source=-1, destination=0) for image in images]\n",
    "#     # preprocess and add pixel_values\n",
    "#     inputs = feature_extractor(images=images)\n",
    "#     examples['pixel_values'] = inputs['pixel_values']\n",
    "#     return examples\n",
    "\n",
    "# features = Features({\n",
    "#     'label': ClassLabel(names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']),\n",
    "#     # 'img': Image(decode=True, id=None),\n",
    "#     # could probably change img to int for faster inference\n",
    "#     'img': Array3D(dtype=\"float32\", shape=(3,32,32)),\n",
    "#     'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)), })\n",
    "\n",
    "# # preprocessed_train = dataset['train'].map(preprocess_images, batched=True, features=features)\n",
    "# preprocessed_val = dataset['validation'].map(preprocess_images, batched=True, features=features)\n",
    "# # preprocessed_test = dataset['test'].map(preprocess_images, batched=True, features=features)\n",
    "# preprocessed_splitted_train = dataset['splitted_train'].map(preprocess_images, batched=True, features=features)\n",
    "\n",
    "# # set format to PyTorch\n",
    "# # preprocessed_train.set_format('torch', columns=['img', 'pixel_values', 'label'])\n",
    "# preprocessed_val.set_format('torch', columns=['img', 'pixel_values', 'label'])\n",
    "# # preprocessed_test.set_format('torch', columns=['img', 'pixel_values', 'label'])\n",
    "# preprocessed_splitted_train.set_format('torch', columns=['img', 'pixel_values', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_dataloaders = {}\n",
    "# preprocessed_dataloaders['splitted_train'] = torch.utils.data.DataLoader(preprocessed_splitted_train, batch_size=batch_size, shuffle=True)\n",
    "# preprocessed_dataloaders['validation'] = torch.utils.data.DataLoader(preprocessed_val, batch_size=batch_size)\n",
    "# preprocessed_dataloaders['test'] = torch.utils.data.DataLoader(preprocessed_test, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# teacher_input = next(iter(preprocessed_dataloaders['splitted_train']))\n",
    "# start = time.time()\n",
    "# with torch.no_grad():\n",
    "#     teacher_output = teacher(teacher_input['pixel_values'])\n",
    "# total = time.time() - start\n",
    "# print(total)\n",
    "# print(teacher_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_saved = torch.load(os.path.join('inference', 'splitted_train.pt'))[0][1]\n",
    "# print(teacher)\n",
    "# teacher_input = preprocessed_dataloaders['splitted_train'].dataset\n",
    "# # print(teacher(teacher_input))\n",
    "# # print(teacher_input['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# student_input = next(iter(preprocessed_dataloaders['test']))  \n",
    "# start = time.time()\n",
    "# student_output = student(student_input['img'])\n",
    "# total = time.time()-start\n",
    "# print(total)\n",
    "# print(student_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_calculator = LossCalulcator(temperature, alpha)\n",
    "optimizer = optim.Adam(\n",
    "    student.parameters(),\n",
    "    lr=lr)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer = optimizer,\n",
    "                                    # step_size = lr_stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare teacher, only need to run once\n",
    "# teacher_outputs = []\n",
    "# with torch.no_grad():\n",
    "#     for images,labels in (preprocessed_dataloaders['raw_train']):\n",
    "#         # images = [np.array(image, dtype=np.uint8) for image in images]\n",
    "#         # images = [np.moveaxis(image, source=-1, destination=0) for image in images]\n",
    "#         teacher_inputs = feature_extractor(images=images, return_tensors='pt', do_rescale=False)\n",
    "#         teacher_outputs.append(teacher(**teacher_inputs).logits)\n",
    "\n",
    "# torch.save(teacher_outputs, os.path.join('inference', 'train.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(student = student,\n",
    "    teacher = teacher,\n",
    "    dataloader = preprocessed_dataloaders['train'],\n",
    "    val_dataloader = preprocessed_dataloaders['test'],\n",
    "    optimizer = optimizer,\n",
    "    # scheduler = scheduler,\n",
    "    loss_calculator = loss_calculator,\n",
    "    epochs = epochs,\n",
    "    device = device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_test = dataset['test'].map(preprocess_images, batched=True, features=features)\n",
    "# preprocessed_test.set_format('torch', columns=['img', 'pixel_values', 'label'])\n",
    "# preprocessed_dataloaders['test'] = torch.utils.data.DataLoader(preprocessed_test, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "evaluate_model(preprocessed_dataloaders['test'], student, loss_fn, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
